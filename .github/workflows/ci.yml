name: Comprehensive CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  PYTHON_VERSION: "3.11"
  REGISTRY: ghcr.io

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ========================================
  # STAGE 1: CODE QUALITY & LINTING
  # ========================================
  lint:
    name: Lint & Format Check
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lint-${{ hashFiles('**/requirements-dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-lint-
            ${{ runner.os }}-pip-

      - name: Install linting dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff black
          if [ -f API/requirements-dev.txt ]; then pip install -r API/requirements-dev.txt; fi

      - name: Run Ruff linter
        run: ruff check . --exit-zero

      - name: Run Ruff formatter check
        run: ruff format . --check

      - name: Run Black formatter check
        run: black . --check

  # ========================================
  # STAGE 2: TYPE CHECKING & TESTS
  # ========================================
  test:
    name: Unit Tests & Coverage
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: read
      pull-requests: read

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: dinoair
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: dinoair_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-test-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-test-
            ${{ runner.os }}-pip-

      - name: Install test dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pytest-xdist
          if [ -f API/requirements-dev.txt ]; then pip install -r API/requirements-dev.txt; fi
          if [ -f API/requirements.txt ]; then pip install -r API/requirements.txt; fi

      - name: Run pytest with coverage
        env:
          DATABASE_URL: postgresql://dinoair:testpass@localhost:5432/dinoair_test
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest \
            --cov=. \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --junitxml=test-results.xml \
            -v

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@e28ff129e5465c2c0dcc6f003fc735cb6ae0c673  # v4.5.0
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            coverage.xml
            test-results.xml
            htmlcov/

  # ========================================
  # STAGE 3: SECURITY SCANNING
  # ========================================
  security:
    name: Security Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read
      security-events: write

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-security-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-security-
            ${{ runner.os }}-pip-

      - name: Install security tools
        run: |
          python -m pip install --upgrade pip
          pip install bandit semgrep
          if [ -f API/requirements-dev.txt ]; then pip install -r API/requirements-dev.txt; fi
          if [ -f API/requirements.txt ]; then pip install -r API/requirements.txt; fi

      - name: Run Bandit security scan
        run: |
          bandit -r . \
            -ll \
            -f json \
            -o bandit-report.json \
            --exclude "venv,.venv,migrations" || true
        continue-on-error: true

      - name: Run Semgrep security scan
        run: |
          semgrep --config=p/python --config=p/security-audit --json -o semgrep-report.json . || true
        continue-on-error: true

      - name: Upload security reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit-report.json
            semgrep-report.json

  # ========================================
  # STAGE 4: CODE ANALYSIS (SonarCloud)
  # ========================================
  sonarcloud:
    name: SonarCloud Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: read
      pull-requests: read

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-sonar-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-sonar-
            ${{ runner.os }}-pip-

      - name: Cache SonarCloud packages
        uses: actions/cache@v3
        with:
          path: ~/.sonar/cache
          key: ${{ runner.os }}-sonar-${{ github.ref }}
          restore-keys: |
            ${{ runner.os }}-sonar-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov bandit
          if [ -f API/requirements-dev.txt ]; then pip install -r API/requirements-dev.txt; fi
          if [ -f API/requirements.txt ]; then pip install -r API/requirements.txt; fi

      - name: Run tests with coverage
        env:
          DATABASE_URL: sqlite:///test.db
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest \
            --cov=. \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=test-results.xml

      - name: Run Bandit for security hotspots
        run: |
          bandit -r . \
            -ll \
            -f json \
            -o bandit-report.json \
            --exclude "venv,.venv,migrations" || true
        continue-on-error: true

      - name: Fix coverage report paths
        run: |
          if [ -f coverage.xml ]; then
            sed -i 's|<source>.*</source>|<source>.</source>|g' coverage.xml
          fi

      - name: SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@e44258b109568baa0df60ed515909fc6c72cba92  # v2.2.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        if: env.SONAR_TOKEN != ''
        with:
          args: >
            -Dsonar.python.coverage.reportPaths=coverage.xml
            -Dsonar.python.xunit.reportPath=test-results.xml
            -Dsonar.python.bandit.reportPaths=bandit-report.json
            -Dsonar.sources=.
            -Dsonar.tests=tests/
            -Dsonar.projectKey=Dino-pit-studios-llc_DinoAir3
            -Dsonar.organization=dino-pit-studios-llc
            -Dsonar.python.version=3.11
            -Dsonar.qualitygate.wait=true

  # ========================================
  # STAGE 5: SELF-HOSTED SONARQUBE (OPTIONAL)
  # ========================================
  sonarqube-selfhosted:
    name: SonarQube Self-Hosted Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: read
    if: vars.SONARQUBE_ENABLED == 'true'

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-sonarqube-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-sonarqube-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov
          if [ -f API/requirements-dev.txt ]; then pip install -r API/requirements-dev.txt; fi
          if [ -f API/requirements.txt ]; then pip install -r API/requirements.txt; fi

      - name: Generate coverage reports
        env:
          DATABASE_URL: sqlite:///test.db
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest \
            --cov=. \
            --cov-report=xml \
            --cov-report=term-missing

      - name: Download SonarQube Scanner
        run: |
          mkdir -p sonar-scanner-bin
          wget -q -O sonar-scanner-bin/sonar-scanner.zip \
            https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.8.0.2856-linux.zip
          unzip -q sonar-scanner-bin/sonar-scanner.zip -d sonar-scanner-bin/
          chmod +x sonar-scanner-bin/sonar-scanner-4.8.0.2856-linux/bin/sonar-scanner

      - name: Run SonarQube Scanner
        env:
          SONAR_HOST_URL: ${{ secrets.SONARQUBE_HOST_URL }}
          SONAR_LOGIN: ${{ secrets.SONARQUBE_TOKEN }}
          SONAR_PROJECT_KEY: ${{ vars.SONARQUBE_PROJECT_KEY }}
        run: |
          sonar-scanner-bin/sonar-scanner-4.8.0.2856-linux/bin/sonar-scanner \
            -Dsonar.projectKey=${{ vars.SONARQUBE_PROJECT_KEY }} \
            -Dsonar.sources=. \
            -Dsonar.tests=tests/ \
            -Dsonar.host.url=${{ secrets.SONARQUBE_HOST_URL }} \
            -Dsonar.login=${{ secrets.SONARQUBE_TOKEN }} \
            -Dsonar.python.coverage.reportPaths=coverage.xml \
            -Dsonar.python.version=3.11 \
            -Dsonar.branch.name=${{ github.ref_name }} \
            -Dsonar.qualitygate.wait=false
        if: env.SONAR_HOST_URL != '' && env.SONAR_LOGIN != ''

  # ========================================
  # STAGE 6: BUILD DOCKER IMAGE
  # ========================================
  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [lint, test, security, sonarcloud]
    permissions:
      contents: read
      packages: write
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@988b5a0280414f521da01fcc63a27aeeb4b104db  # v3.6.1

      - name: Log in to Container Registry
        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567  # v3.3.0
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@8e5442c4ef9f78752691e2d8f8d19755c6f78e81  # v5.5.1
        with:
          images: ${{ env.REGISTRY }}/${{ github.repository }}
          tags: |
            type=ref,event=branch
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-

      - name: Build and push Docker image
        uses: docker/build-push-action@5176d81f87c23d6fc96624dfdbcd9f3830bbe445  # v6.5.0
        with:
          context: .
          file: ./Dockerfile.mcp
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # ========================================
  # STAGE 7: DEPLOYMENT (PLACEHOLDER)
  # ========================================
  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    timeout-minutes: 15
    permissions:
      contents: read

    steps:
      - uses: actions/checkout@v4

      - name: Deployment placeholder
        run: |
          echo "ðŸš€ Deployment workflow ready"
          echo "Configure deployment target (AWS, GCP, Heroku, DigitalOcean, etc.)"
          echo "Add deployment steps based on your infrastructure"
